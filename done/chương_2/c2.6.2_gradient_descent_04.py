# import thÆ° viá»‡n 
import numpy as np
import matplotlib.pyplot as plt

# 1. Äá»‹nh nghÄ©a hÃ m loss
# Giáº£ sá»­ mÃ¬nh cÃ³ hÃ m loss ğ“›(Î¸) = Î¸â´ - 6Î¸Â² + 4Î¸ + 20
# khai bÃ¡o hÃ m loss
def cal_loss_function(theta):
    return theta**4 - 6*theta**2 + 4*theta + 20

# Äáº¡o hÃ m cá»§a hÃ m Loss ğ“›â€²(Î¸) = 4Î¸Â³ - 12Î¸ + 4 (Ä‘áº¡o hÃ m cá»§a Î¸â´ - 6Î¸Â² + 4Î¸ + 20))
def cal_loss_derivative(theta):
    return 4*theta**3 - 12*theta + 4

# 2. Váº½ Ä‘á»“ thá»‹ hÃ m loss
#Khai bÃ¡o khoáº£ng giÃ¡ trá»‹ cá»§a theta
theta_values = np.linspace(-3, 3, 400)

#giÃ¡ trá»‹ cá»§a hÃ m loss theo khoáº£ng theta
loss_values = cal_loss_function(theta_values)

#Váº½ Ä‘á»“ thá»‹ hÃ m loss
plt.plot(theta_values, loss_values)

# 3. Khá»Ÿi táº¡o
# Khá»Ÿi táº¡o giÃ¡ trá»‹ ban Ä‘áº§u cá»§a theta 
theta = 2.8
# Khá»Ÿi táº¡o siÃªu tham sá»‘ - hyperparameters
learning_rate = 0.01
# epsilon = 1e-4 
N = 100 # sá»‘ vÃ²ng láº·p

#Khai bÃ¡o thÃªm
beta = 0.9
v = 0  # Váº­n tá»‘c ban Ä‘áº§u

# cÃ¡ch 2: Khai bÃ¡o sá»‘ vÃ²ng láº·p
for i in range(N):
    #tÃ­nh giÃ¡ trá»‹ hÃ m loss
    loss = cal_loss_function(theta)

    #tÃ­nh giÃ¡ trá»‹ Ä‘áº¡o hÃ m cá»§a hÃ m loss theo theta
    grad = cal_loss_derivative(theta)

    # Váº½ Ä‘iá»ƒm theta hiá»‡n táº¡i 
    plt.plot(theta, loss, 'ro') # ro lÃ  Ä‘iá»ƒm trÃ²n mÃ u Ä‘á»

    #Dá»«ng Ä‘á»ƒ quan sÃ¡t
    plt.pause(0.1)

    
    # Cáº­p nháº­t theta
    # theta = theta - learning_rate * grad
    
    # tÃ­nh váº­n tá»‘c
    v = beta*v + (1 - beta) * grad

    # cáº­p nháº­t theta
    theta = theta - learning_rate*v

plt.show()
print("GiÃ¡ trá»‹ theta tá»‘i Æ°u::::", theta)


